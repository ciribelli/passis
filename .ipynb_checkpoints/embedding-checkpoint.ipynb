{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "503cdfef-bf7c-4e89-963f-a5e5c6af0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.replace('\\n', ' ')\n",
    "    serie = serie.replace('\\\\n', ' ')\n",
    "    serie = serie.replace('\\r', ' ')\n",
    "    serie = serie.replace('\\r', ' ')\n",
    "    serie = serie.replace('    ', ' ')\n",
    "    serie = serie.replace('   ', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    serie = serie.replace('-', ' ')\n",
    "    serie = serie.replace(',', ' ')\n",
    "    serie = serie.replace('_', ' ')\n",
    "    serie = serie.replace('üìù', '')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "df55f8d3-109a-41cf-a96b-5e42f270b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "url = \"https://passis-bfd9b877f7d0.herokuapp.com/\"\n",
    "\n",
    "table_list = ['memorias', 'recuperar_lista_documentos']\n",
    "\n",
    "payload = {}\n",
    "headers = {}\n",
    "\n",
    "resultados = []  # Lista para armazenar os valores concatenados de todas as linhas\n",
    "\n",
    "for table in table_list:\n",
    "    n_url = url + table\n",
    "    response = requests.request(\"GET\", n_url, headers=headers, data=payload)\n",
    "    data = json.loads(response.text)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Iterar pelas linhas do DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        concatenated_values = ''\n",
    "        # Iterar pelas colunas e adicionar o nome da coluna e o valor √† string\n",
    "        for col_name in df.columns:\n",
    "            concatenated_values += col_name + ': ' + remove_newlines(str(row[col_name])) + '. '\n",
    "        # Adicionar o nome da tabela, o ID (√≠ndice) e o conte√∫do concatenado √† lista de resultados\n",
    "        resultados.append([table, index, concatenated_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1cc0c389-f5fc-4f07-b922-edf84a4bdab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       tabela  index  \\\n",
      "0                    memorias      0   \n",
      "1                    memorias      1   \n",
      "2  recuperar_lista_documentos      0   \n",
      "3  recuperar_lista_documentos      1   \n",
      "\n",
      "                                               texto  \n",
      "0  content: perguntas para gartner:   percentual ...  \n",
      "1  content:  esse √© meu primeiro registro de mem√≥...  \n",
      "2  data_de_upload: 2023 09 10 00:26:46. descricao...  \n",
      "3  data_de_upload: 2023 09 10 00:31:07. descricao...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabela</th>\n",
       "      <th>index</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memorias</td>\n",
       "      <td>0</td>\n",
       "      <td>content: perguntas para gartner:   percentual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>memorias</td>\n",
       "      <td>1</td>\n",
       "      <td>content:  esse √© meu primeiro registro de mem√≥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recuperar_lista_documentos</td>\n",
       "      <td>0</td>\n",
       "      <td>data_de_upload: 2023 09 10 00:26:46. descricao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recuperar_lista_documentos</td>\n",
       "      <td>1</td>\n",
       "      <td>data_de_upload: 2023 09 10 00:31:07. descricao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tabela  index  \\\n",
       "0                    memorias      0   \n",
       "1                    memorias      1   \n",
       "2  recuperar_lista_documentos      0   \n",
       "3  recuperar_lista_documentos      1   \n",
       "\n",
       "                                               texto  \n",
       "0  content: perguntas para gartner:   percentual ...  \n",
       "1  content:  esse √© meu primeiro registro de mem√≥...  \n",
       "2  data_de_upload: 2023 09 10 00:26:46. descricao...  \n",
       "3  data_de_upload: 2023 09 10 00:31:07. descricao...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(resultados, columns=['tabela', 'index', 'texto'])\n",
    "\n",
    "# Agora voc√™ tem um DataFrame 'df' com as colunas 'tabela', 'index' e 'texto'\n",
    "print(df)\n",
    "df.to_csv('resultados.csv', index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "de7b6095-ea2c-4ef0-9ad6-c7a2de4fc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "431a53f8-8022-4f3f-96c2-a964efd72aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_tokens'] = df.texto.apply(lambda x: len(tokenizer.encode(x)))\n",
    "max_tokens = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4fa53f4-6d47-4f47-9cd2-6f215e30dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "    print('--------------------', sentences)\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    print(n_tokens)\n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater\n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of\n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "39434470-1622-4e84-8679-f1ed3f67ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened = []\n",
    "\n",
    "# Loop through the dataframe\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # If the text is None, go to the next row\n",
    "    if row[1]['texto'] is None:\n",
    "        continue\n",
    "\n",
    "    # If the number of tokens is greater than the max number of tokens, split the text into chunks\n",
    "    if row[1]['n_tokens'] > max_tokens:\n",
    "        shortened += split_into_many(row[1]['texto'])\n",
    "\n",
    "    # Otherwise, add the text to the list of shortened texts\n",
    "    else:\n",
    "        shortened.append( row[1]['texto'] )\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(shortened, columns = ['texto'])\n",
    "df2['n_tokens'] = df.texto.apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c854f4ca-1279-4575-9015-fabdfc70e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> content: perguntas para gartner:   percentual de empresas investindo em fine tuning   divis√£o de estrat√©gia entre foundation models  domain models and model hubs.. date_created: 2023 09 23 17:37:47. id: 2.  \n",
      "\n",
      "> content:  esse √© meu primeiro registro de mem√≥ria. date_created: 2023 09 23 15:22:08. id: 1.  \n",
      "\n",
      "> data_de_upload: 2023 09 10 00:26:46. descricao: Identidade civil ou Registro Geral N√∫mero do documento: MG10192099. id: 5. nome_do_documento: RG. versao: 1.  \n",
      "\n",
      "> data_de_upload: 2023 09 10 00:31:07. descricao: Passaporte n√∫mero: GD208356 Data de expedi√ß√£o: 05/11/2021 Validade: 04/11/2031. id: 6. nome_do_documento: Passaporte. versao: 1.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df2['texto']:\n",
    "    print (\">\", i, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e43acf8b-ac00-43b1-9fbd-019b7de698ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabela</th>\n",
       "      <th>index</th>\n",
       "      <th>texto</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memorias</td>\n",
       "      <td>0</td>\n",
       "      <td>content: perguntas para gartner:   percentual ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>memorias</td>\n",
       "      <td>1</td>\n",
       "      <td>content:  esse √© meu primeiro registro de mem√≥...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recuperar_lista_documentos</td>\n",
       "      <td>0</td>\n",
       "      <td>data_de_upload: 2023 09 10 00:26:46. descricao...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recuperar_lista_documentos</td>\n",
       "      <td>1</td>\n",
       "      <td>data_de_upload: 2023 09 10 00:31:07. descricao...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tabela  index  \\\n",
       "0                    memorias      0   \n",
       "1                    memorias      1   \n",
       "2  recuperar_lista_documentos      0   \n",
       "3  recuperar_lista_documentos      1   \n",
       "\n",
       "                                               texto  n_tokens  \n",
       "0  content: perguntas para gartner:   percentual ...        58  \n",
       "1  content:  esse √© meu primeiro registro de mem√≥...        35  \n",
       "2  data_de_upload: 2023 09 10 00:26:46. descricao...        55  \n",
       "3  data_de_upload: 2023 09 10 00:31:07. descricao...        72  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "40aa182a-ca46-432c-820c-82c44b2645dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content: perguntas para gartner:   percentual ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content:  esse √© meu primeiro registro de mem√≥...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_de_upload: 2023 09 10 00:26:46. descricao...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_de_upload: 2023 09 10 00:31:07. descricao...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  n_tokens\n",
       "0  content: perguntas para gartner:   percentual ...        58\n",
       "1  content:  esse √© meu primeiro registro de mem√≥...        35\n",
       "2  data_de_upload: 2023 09 10 00:26:46. descricao...        55\n",
       "3  data_de_upload: 2023 09 10 00:31:07. descricao...        72"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a5dab623-b570-4f5c-a010-574d969f8996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabela</th>\n",
       "      <th>index</th>\n",
       "      <th>texto</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memorias</td>\n",
       "      <td>0</td>\n",
       "      <td>content: perguntas para gartner:   percentual ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[0.011579838581383228, -0.0010901413625106215,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>memorias</td>\n",
       "      <td>1</td>\n",
       "      <td>content:  esse √© meu primeiro registro de mem√≥...</td>\n",
       "      <td>35</td>\n",
       "      <td>[-0.012386146001517773, -0.0006594319129362702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recuperar_lista_documentos</td>\n",
       "      <td>0</td>\n",
       "      <td>data_de_upload: 2023 09 10 00:26:46. descricao...</td>\n",
       "      <td>55</td>\n",
       "      <td>[-0.026302412152290344, 0.011552642099559307, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recuperar_lista_documentos</td>\n",
       "      <td>1</td>\n",
       "      <td>data_de_upload: 2023 09 10 00:31:07. descricao...</td>\n",
       "      <td>72</td>\n",
       "      <td>[-0.022375211119651794, 0.01720244623720646, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tabela  index  \\\n",
       "0                    memorias      0   \n",
       "1                    memorias      1   \n",
       "2  recuperar_lista_documentos      0   \n",
       "3  recuperar_lista_documentos      1   \n",
       "\n",
       "                                               texto  n_tokens  \\\n",
       "0  content: perguntas para gartner:   percentual ...        58   \n",
       "1  content:  esse √© meu primeiro registro de mem√≥...        35   \n",
       "2  data_de_upload: 2023 09 10 00:26:46. descricao...        55   \n",
       "3  data_de_upload: 2023 09 10 00:31:07. descricao...        72   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.011579838581383228, -0.0010901413625106215,...  \n",
       "1  [-0.012386146001517773, -0.0006594319129362702...  \n",
       "2  [-0.026302412152290344, 0.011552642099559307, ...  \n",
       "3  [-0.022375211119651794, 0.01720244623720646, 0...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = ('xxxxxxx')\n",
    "\n",
    "df['embeddings'] = df.texto.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "df.to_csv('embeddings.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d5768ca-0c9d-4c55-b6ef-dace9249a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 58 \n",
      "\n",
      "> 35 \n",
      "\n",
      "> 55 \n",
      "\n",
      "> 72 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df['n_tokens']:\n",
    "    print (\">\", i, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
